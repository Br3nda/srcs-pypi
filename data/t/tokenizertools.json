{
  "latest_version": [
    "0.1a"
  ],
  "meta": {
    "description": "Implements lexical analyzers as iterators yielding tokens",
    "homepage": "http://github.com/dbc/tokenizertools",
    "license": "BSD"
  },
  "versions": {
    "0.1a": {
      "sha256": "bd0238545f7275b670d71ce3fd899c8b5a81febb0faefcf2d4052ad20d140301",
      "url": "https://files.pythonhosted.org/packages/41/b8/a06793517fc55f0865cb47f2e6d93c62bb0f980684a5f807eca59608a32a/tokenizertools-0.1a.tar.gz"
    }
  }
}